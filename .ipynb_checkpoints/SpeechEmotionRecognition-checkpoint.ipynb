{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition using Librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function extract_feature to extract the mfcc, chroma, and mel features from a sound file. This function takes 4 parameters- the file name and three Boolean parameters for the three features:\n",
    "\n",
    "    - mfcc: Mel Frequency Cepstral Coefficient, represents the short-term power spectrum of a sound\n",
    "    - chroma: Pertains to the 12 different pitch classes\n",
    "    - mel: Mel Spectrogram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract features (mfcc, chroma, mel) from a sound file\n",
    "\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "#Emotions to observe\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data and extract features for each sound file\n",
    "def load_data():\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"/Users/zaid/Desktop/Speech Emotion Recognition ML Proj/speech-emotion-recognition-ravdess-data/Actor_*/*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return x,y\n",
    "    #return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-537.004395</td>\n",
       "      <td>31.666399</td>\n",
       "      <td>-6.542091</td>\n",
       "      <td>4.567605</td>\n",
       "      <td>-7.387805</td>\n",
       "      <td>-13.684702</td>\n",
       "      <td>-17.860582</td>\n",
       "      <td>-11.828494</td>\n",
       "      <td>-0.225548</td>\n",
       "      <td>-11.868469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-383.007202</td>\n",
       "      <td>9.420697</td>\n",
       "      <td>-26.200880</td>\n",
       "      <td>2.628421</td>\n",
       "      <td>-17.898153</td>\n",
       "      <td>-16.619091</td>\n",
       "      <td>-16.220095</td>\n",
       "      <td>-11.781564</td>\n",
       "      <td>-1.197635</td>\n",
       "      <td>-13.881689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-606.815308</td>\n",
       "      <td>42.624638</td>\n",
       "      <td>1.537446</td>\n",
       "      <td>5.558994</td>\n",
       "      <td>-6.486233</td>\n",
       "      <td>-4.224218</td>\n",
       "      <td>-14.775834</td>\n",
       "      <td>-7.948472</td>\n",
       "      <td>-1.429373</td>\n",
       "      <td>-4.777880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-555.719055</td>\n",
       "      <td>43.634399</td>\n",
       "      <td>7.089331</td>\n",
       "      <td>7.287218</td>\n",
       "      <td>-7.250546</td>\n",
       "      <td>-12.701806</td>\n",
       "      <td>-14.231813</td>\n",
       "      <td>-13.405810</td>\n",
       "      <td>0.316495</td>\n",
       "      <td>-10.287708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-526.230774</td>\n",
       "      <td>30.395340</td>\n",
       "      <td>-10.102286</td>\n",
       "      <td>5.732557</td>\n",
       "      <td>-10.387459</td>\n",
       "      <td>-13.651891</td>\n",
       "      <td>-12.542537</td>\n",
       "      <td>-9.009912</td>\n",
       "      <td>0.964212</td>\n",
       "      <td>-7.356021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.001951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>-646.522766</td>\n",
       "      <td>54.202343</td>\n",
       "      <td>10.829182</td>\n",
       "      <td>15.782007</td>\n",
       "      <td>-0.777860</td>\n",
       "      <td>-0.975148</td>\n",
       "      <td>-10.103933</td>\n",
       "      <td>-4.550802</td>\n",
       "      <td>-4.039625</td>\n",
       "      <td>-5.251637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-525.341064</td>\n",
       "      <td>39.242966</td>\n",
       "      <td>-24.850788</td>\n",
       "      <td>14.384969</td>\n",
       "      <td>-11.483785</td>\n",
       "      <td>-7.030712</td>\n",
       "      <td>-12.698215</td>\n",
       "      <td>-8.867377</td>\n",
       "      <td>-2.992077</td>\n",
       "      <td>-9.694036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>-627.105347</td>\n",
       "      <td>47.312954</td>\n",
       "      <td>-5.354202</td>\n",
       "      <td>24.124666</td>\n",
       "      <td>-3.931024</td>\n",
       "      <td>2.508424</td>\n",
       "      <td>-6.277518</td>\n",
       "      <td>-1.511968</td>\n",
       "      <td>-0.450381</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-691.606018</td>\n",
       "      <td>61.090164</td>\n",
       "      <td>12.652380</td>\n",
       "      <td>23.446877</td>\n",
       "      <td>1.102112</td>\n",
       "      <td>9.368806</td>\n",
       "      <td>-1.883122</td>\n",
       "      <td>-3.115121</td>\n",
       "      <td>-2.259609</td>\n",
       "      <td>1.354561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-688.184082</td>\n",
       "      <td>62.583153</td>\n",
       "      <td>19.267427</td>\n",
       "      <td>20.978205</td>\n",
       "      <td>4.599946</td>\n",
       "      <td>9.766887</td>\n",
       "      <td>-6.723453</td>\n",
       "      <td>-2.790007</td>\n",
       "      <td>0.117051</td>\n",
       "      <td>0.670218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5    \\\n",
       "0   -537.004395  31.666399  -6.542091   4.567605  -7.387805 -13.684702   \n",
       "1   -383.007202   9.420697 -26.200880   2.628421 -17.898153 -16.619091   \n",
       "2   -606.815308  42.624638   1.537446   5.558994  -6.486233  -4.224218   \n",
       "3   -555.719055  43.634399   7.089331   7.287218  -7.250546 -12.701806   \n",
       "4   -526.230774  30.395340 -10.102286   5.732557 -10.387459 -13.651891   \n",
       "..          ...        ...        ...        ...        ...        ...   \n",
       "763 -646.522766  54.202343  10.829182  15.782007  -0.777860  -0.975148   \n",
       "764 -525.341064  39.242966 -24.850788  14.384969 -11.483785  -7.030712   \n",
       "765 -627.105347  47.312954  -5.354202  24.124666  -3.931024   2.508424   \n",
       "766 -691.606018  61.090164  12.652380  23.446877   1.102112   9.368806   \n",
       "767 -688.184082  62.583153  19.267427  20.978205   4.599946   9.766887   \n",
       "\n",
       "           6          7         8          9    ...       170       171  \\\n",
       "0   -17.860582 -11.828494 -0.225548 -11.868469  ...  0.000858  0.001073   \n",
       "1   -16.220095 -11.781564 -1.197635 -13.881689  ...  0.004067  0.004942   \n",
       "2   -14.775834  -7.948472 -1.429373  -4.777880  ...  0.000816  0.000669   \n",
       "3   -14.231813 -13.405810  0.316495 -10.287708  ...  0.006458  0.006884   \n",
       "4   -12.542537  -9.009912  0.964212  -7.356021  ...  0.001960  0.002502   \n",
       "..         ...        ...       ...        ...  ...       ...       ...   \n",
       "763 -10.103933  -4.550802 -4.039625  -5.251637  ...  0.000128  0.000130   \n",
       "764 -12.698215  -8.867377 -2.992077  -9.694036  ...  0.000232  0.000190   \n",
       "765  -6.277518  -1.511968 -0.450381   0.038337  ...  0.000038  0.000025   \n",
       "766  -1.883122  -3.115121 -2.259609   1.354561  ...  0.000016  0.000011   \n",
       "767  -6.723453  -2.790007  0.117051   0.670218  ...  0.000073  0.000079   \n",
       "\n",
       "          172       173       174       175       176       177       178  \\\n",
       "0    0.001119  0.001249  0.000946  0.000919  0.001475  0.001867  0.001133   \n",
       "1    0.004713  0.003613  0.003791  0.003923  0.003090  0.002704  0.001470   \n",
       "2    0.000448  0.000357  0.000393  0.000801  0.000465  0.000162  0.000173   \n",
       "3    0.006208  0.006897  0.006973  0.008390  0.007365  0.003125  0.003766   \n",
       "4    0.002561  0.005435  0.005965  0.004992  0.003769  0.004138  0.002868   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763  0.000121  0.000157  0.000140  0.000158  0.000147  0.000090  0.000083   \n",
       "764  0.000173  0.000174  0.000319  0.000201  0.000392  0.000203  0.000125   \n",
       "765  0.000021  0.000023  0.000022  0.000015  0.000011  0.000008  0.000007   \n",
       "766  0.000011  0.000023  0.000024  0.000030  0.000013  0.000008  0.000004   \n",
       "767  0.000106  0.000072  0.000052  0.000049  0.000070  0.000088  0.000118   \n",
       "\n",
       "          179  \n",
       "0    0.000950  \n",
       "1    0.001169  \n",
       "2    0.000086  \n",
       "3    0.003333  \n",
       "4    0.001951  \n",
       "..        ...  \n",
       "763  0.000072  \n",
       "764  0.000086  \n",
       "765  0.000004  \n",
       "766  0.000002  \n",
       "767  0.000046  \n",
       "\n",
       "[768 rows x 180 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "X = pd.DataFrame(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kmeans = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_numeric = [0]*len(y)\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 'fearful':\n",
    "        y_numeric[i] = 3\n",
    "    elif y[i] == 'disgust':\n",
    "        y_numeric[i] = 1\n",
    "    elif y[i] == 'calm':\n",
    "        y_numeric[i] = 2\n",
    "    elif y[i] == 'happy':\n",
    "        y_numeric[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1, 2, 2, 0, 0, 1, 1,\n",
       "       3, 3, 1, 1, 3, 3, 2, 2, 0, 0, 2, 2, 0, 0, 1, 1, 3, 3, 1, 1, 3, 3,\n",
       "       2, 2, 0, 0, 3, 3, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1, 0, 0,\n",
       "       2, 2, 3, 3, 1, 1, 3, 3, 1, 1, 0, 0, 2, 2, 1, 1, 3, 3, 2, 2, 0, 0,\n",
       "       2, 2, 0, 0, 1, 1, 3, 3, 1, 1, 3, 3, 2, 2, 0, 0, 2, 2, 0, 0, 1, 1,\n",
       "       3, 3, 0, 0, 2, 2, 3, 3, 1, 1, 3, 3, 1, 1, 0, 0, 2, 2, 3, 3, 1, 1,\n",
       "       0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1, 2, 2, 0, 0, 1, 1, 3, 3, 1, 1,\n",
       "       3, 3, 2, 2, 0, 0, 2, 2, 0, 0, 1, 1, 3, 3, 1, 1, 3, 3, 2, 2, 0, 0,\n",
       "       3, 3, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1, 0, 0, 2, 2, 3, 3,\n",
       "       1, 1, 3, 3, 1, 1, 0, 0, 2, 2, 1, 1, 3, 3, 2, 2, 0, 0, 2, 2, 0, 0,\n",
       "       1, 1, 3, 3, 1, 1, 3, 3, 2, 2, 0, 0, 2, 2, 0, 0, 1, 1, 3, 3, 0, 0,\n",
       "       2, 2, 3, 3, 1, 1, 3, 3, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1,\n",
       "       3, 3, 1, 1, 0, 0, 2, 2, 1, 1, 3, 3, 2, 2, 0, 0, 2, 2, 0, 0, 1, 1,\n",
       "       3, 3, 1, 1, 3, 3, 2, 2, 0, 0, 2, 2, 0, 0, 1, 1, 3, 3, 0, 0, 2, 2,\n",
       "       3, 3, 1, 1, 3, 3, 1, 1, 0, 0, 2, 2, 3, 3, 1, 1, 0, 0, 2, 2, 0, 0,\n",
       "       2, 2, 3, 3, 1, 1, 2, 2, 0, 0, 1, 1, 3, 3, 1, 1, 3, 3, 2, 2, 0, 0,\n",
       "       2, 2, 0, 0, 1, 1, 3, 3, 1, 1, 3, 3, 2, 2, 0, 0, 3, 3, 1, 1, 0, 0,\n",
       "       2, 2, 0, 0, 2, 2, 3, 3, 1, 1, 2, 2, 0, 0, 1, 1, 3, 3, 1, 1, 3, 3,\n",
       "       2, 2, 0, 0, 3, 3, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1, 3, 3,\n",
       "       1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1, 2, 2, 0, 0, 1, 1, 3, 3,\n",
       "       1, 1, 3, 3, 2, 2, 0, 0, 1, 1, 3, 3, 2, 2, 0, 0, 2, 2, 0, 0, 1, 1,\n",
       "       3, 3, 0, 0, 2, 2, 3, 3, 1, 1, 3, 3, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2,\n",
       "       3, 3, 1, 1, 3, 3, 1, 1, 0, 0, 2, 2, 1, 1, 3, 3, 2, 2, 0, 0, 2, 2,\n",
       "       0, 0, 1, 1, 3, 3, 3, 3, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1,\n",
       "       2, 2, 0, 0, 1, 1, 3, 3, 1, 1, 3, 3, 2, 2, 0, 0, 1, 1, 3, 3, 2, 2,\n",
       "       0, 0, 2, 2, 0, 0, 1, 1, 3, 3, 0, 0, 2, 2, 3, 3, 1, 1, 3, 3, 1, 1,\n",
       "       0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1, 3, 3, 1, 1, 0, 0, 2, 2, 1, 1,\n",
       "       3, 3, 2, 2, 0, 0, 2, 2, 0, 0, 1, 1, 3, 3, 3, 3, 1, 1, 0, 0, 2, 2,\n",
       "       0, 0, 2, 2, 3, 3, 1, 1, 2, 2, 0, 0, 1, 1, 3, 3, 1, 1, 3, 3, 2, 2,\n",
       "       0, 0, 0, 0, 2, 2, 3, 3, 1, 1, 3, 3, 1, 1, 0, 0, 2, 2, 1, 1, 3, 3,\n",
       "       2, 2, 0, 0, 2, 2, 0, 0, 1, 1, 3, 3, 2, 2, 0, 0, 1, 1, 3, 3, 1, 1,\n",
       "       3, 3, 2, 2, 0, 0, 3, 3, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1,\n",
       "       3, 3, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 3, 3, 1, 1, 2, 2, 0, 0, 1, 1,\n",
       "       3, 3, 1, 1, 3, 3, 2, 2, 0, 0, 1, 1, 3, 3, 2, 2, 0, 0, 2, 2, 0, 0,\n",
       "       1, 1, 3, 3, 0, 0, 2, 2, 3, 3, 1, 1, 3, 3, 1, 1, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_numeric = np.array(y_numeric)\n",
    "y_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.49%\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true = y_numeric, y_pred = y_kmeans)\n",
    "\n",
    "#Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X, y, test_size=0.20, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 180)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 154)\n"
     ]
    }
   ],
   "source": [
    "#Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "#Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gnb = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.91%\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred_gnb)\n",
    "#Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = svm.SVC()\n",
    "model2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 42.21%\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred_svc)\n",
    "#Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.70%\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred_rf)\n",
    "#Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.95%\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred_dt)\n",
    "#Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_perceptron = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 38.31%\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Calculate the accuracy of model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred_perceptron)\n",
    "#DataFlair - Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the test set\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.73%\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "#DataFlair - Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
